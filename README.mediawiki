= Synopsis =
These are the features that control basic Nginx functionality.


= Directives =
== daemon ==
'''Syntax:''' ''daemon on | off''

'''Default:''' ''on''

<geshi lang="nginx">
daemon  off;
</geshi>

Do not use the [[#daemon|daemon]] or [[#master_process|master_process]] directives in a production mode; these options are used for development only. You can use <code>daemon off</code> safely in production mode with runit/daemontools, however you can't do a graceful upgrade. <code>master_process off</code> should never be used in production.

== env ==
'''Syntax:''' ''env VAR|VAR=VALUE''

'''Default:''' ''TZ''

'''Context:''' ''main''

The instruction allows to limit a set of variables of environment, to change it values or to create new variables for following cases:

* inheritance of variables during [[NginxCommandLine#utnbotf| upgrading the binary with zero downtime]] ;
* for use by the [[NginxEmbeddedPerlModule|embedded Perl module]] 
* for use by working processes. However it is necessary to keep in mind, that management of behaviour of system libraries in a similar way probably not always as frequently libraries use variables only during initialization, that is still before they can be set by means of the given instruction. Exception to it is the above described updating an executed file with zero downtime.

If variable TZ is not described obviously it is always inherited and is always accessible to the [[NginxEmbeddedPerlModule|embedded Perl module]].

Example of use:
<geshi lang="nginx">
env  MALLOC_OPTIONS;
env  PERL5LIB=/data/site/modules;
env  OPENSSL_ALLOW_PROXY_CERTS=1;
</geshi>

== debug_points ==
'''Syntax:''' ''debug_points [stop | abort] ''

'''Default:''' ''none''

<geshi lang="nginx">
debug_points stop;
</geshi>

There are some assertion points inside nginx that allow to stop nginx to attach the debugger, or to abort and to create the core file.

== error_log ==
'''Syntax:''' ''error_log file [ debug | info | notice | warn | error | crit ] ''

'''Default:''' ''${prefix}/logs/error.log''

Specifies the file where server (and fastcgi) errors are logged.

Default values for the error level:

#  in the main section - <code>error</code>
#  in the HTTP section - <code>crit</code>
#  in the server section - <code>crit</code>

Nginx supports separate error logging per virtual host. This is a unique feature, which [http://www.wikivs.com/wiki/Lighttpd_vs_nginx#Separated_error_logging_per_virtual_server lighttpd refuses to implement]. For an example of separate error logging per server, see [[SeparateErrorLoggingPerVirtualHost]] and this [http://thread.gmane.org/gmane.comp.web.nginx.english/9097/focus=9099 mailing list thread on separating error logging per virtual host].

If you've built Nginx with <code>--with-debug</code>, you may also use:
<geshi lang="nginx">
error_log LOGFILE [debug_core | debug_alloc | debug_mutex | debug_event | debug_http | debug_imap];
</geshi>

Note that <code>error_log off</code> does not disable logging - the log will be written to a file named "off". To disable logging, you may use:
<geshi lang="nginx">
error_log /dev/null crit;
</geshi>

Also note that as of version 0.7.53, nginx will use a compiled-in default error log location until it has read the config file. If the user running nginx doesn't have write permission to this log location, nginx will raise an alert like this:

<geshi lang="text">
[alert]: could not open error log file: open() "/var/log/nginx/error.log" failed (13: Permission denied)
</geshi>

== include ==
'''Syntax:''' ''include file | *''

'''Default:''' ''none''

You can include any configuration files for what ever purpose you want.  

Since 0.4.4, the <code>include</code> directive also supports filename globbing:
<geshi lang="nginx">
include vhosts/*.conf;
</geshi>

Note that until version 0.6.7, paths are relative to what was specified to <code>configure</code> via the <code>--prefix=<PATH></code> directive, which by default is <code>/usr/local/nginx</code>.  If you didn't set this when you compiled Nginx, then use absolute paths. 

Since version 0.6.7, paths are relative to directory of nginx configuration file nginx.conf, but not to nginx prefix directory.

== lock_file ==
'''Syntax:''' ''lock_file file''

'''Default:''' ''compile-time option''

<geshi lang="nginx">
lock_file  /var/log/lock_file;
</geshi>
nginx uses accept mutex to serialize accept() syscalls. If nginx is built by gcc, Intel C++, or SunPro C++ compilers on i386, amd64, sparc64, and ppc64, then nginx uses the atomic instructions to implement the mutex. In other cases the lock file would be used.


== master_process ==
'''Syntax:''' ''master_process on | off''

'''Default:''' ''on''

<geshi lang="nginx">
master_process  off;
</geshi>
Do not use the "daemon" and "master_process" directives in a production mode, these options are mainly used for development only.

== pid ==
'''Syntax:''' ''pid file''

'''Default:''' ''compile-time option''

Example:
<geshi lang="nginx">
pid /var/log/nginx.pid;
</geshi>
The pid-file. It can be used for the kill-command to send signals to nginx, eg: to reload the config: <code>kill -HUP `cat /var/log/nginx.pid`</code>

== ssl_engine ==
'''Syntax:''' ''ssl_engine engine''

'''Default:''' ''system dependent''

Here you can set your preferred openssl engine if any available. You can figure out which one do you have with the commandline tool: <code>openssl engine -t</code>

For example:

<pre>
$ openssl engine -t
(cryptodev) BSD cryptodev engine
  [ available ] 
(dynamic) Dynamic engine loading support
  [ unavailable ] 
</pre>

== timer_resolution ==
'''Syntax:''' ''timer_resolution t''

'''Default:''' ''none''

Example:
<geshi lang="nginx">
timer_resolution  100ms;
</geshi>
The directive allows to decrease number gettimeofday() syscalls. By default gettimeofday() is called after each return from kevent(), epoll, /dev/poll, select(), poll().

But if you need an exact time in logs when logging $upstream_response_time, or $msec variables, then you should use <code>timer_resolution</code>.



== user ==
'''Syntax:''' ''user user [group] ''

'''Default:''' ''nobody nobody''

If the master process is run as root, then nginx will setuid()/setgid() to USER/GROUP. If GROUP is not specified, then nginx uses the same name as USER. By default it's <code>nobody</code> user and <code>nobody</code> or <code>nogroup</code> group or the <code>--user=USER</code> and <code>--group=GROUP</code> from the <code>./configure</code> script.

Example:
<geshi lang="nginx">
user www users;
</geshi>



== worker_cpu_affinity ==
'''Syntax:''' ''worker_cpu_affinity cpumask [cpumask...] ''

'''Default:''' ''none''

Linux only.

With this option you can bind the worker process to a CPU, it calls sched_setaffinity(). 

For example,
<geshi lang="nginx">
worker_processes     4;
worker_cpu_affinity 0001 0010 0100 1000;
</geshi>

Bind each worker process to one CPU only.
<geshi lang="nginx">
worker_processes     2;
worker_cpu_affinity 0101 1010;
</geshi>

Bind the first worker to CPU0/CPU2, bind the second worker to CPU1/CPU3. This is suitable for HTT.



==  worker_priority ==
'''Syntax:''' ''worker_priority [-] number''

'''Default:''' ''on''

With this option you can give to all worker processes the priority (nice) you need/wish, it calls setpriority().



==  worker_processes ==
'''Syntax:''' ''worker_processes number''

'''Default:''' ''1''

e.g.:
<geshi lang="nginx">
worker_processes 4;
</geshi>

A worker process is a single-threaded process.

If Nginx is doing CPU-intensive work such as SSL or gzipping and you have 2 or more CPUs/cores, then you may set worker_processes to be equal to the number of CPUs or cores.

If you are serving a lot of static files and the total size of the files is bigger than the available memory, then you may increase worker_processes to fully utilize disk bandwidth.

Your OS may schedule all workers on single CPU/core this can be avoided using [[CoreModule#worker_cpu_affinity|worker_cpu_affinity]].

Nginx has the ability to use more than one worker process for several reasons:

#  to use SMP
#  to decrease latency when workers blockend on disk I/O
#  to limit number of connections per process when select()/poll() is used

The <code>worker_processes</code> and <code>worker_connections</code> from the event sections allows you to calculate <code>maxclients</code> value:

max_clients = worker_processes * worker_connections

== worker_rlimit_core ==
'''Syntax:''' ''worker_rlimit_core size''

'''Default:''' '' ''

Maximum size of core file per worker. Used for [[Debugging]] Nginx.

== worker_rlimit_nofile ==
'''Syntax:''' ''worker_rlimit_nofile limit''

'''Default:''' ''No value specified, so OS default.''

Specifies the value for maximum file descriptors that can be opened by this  process.

== worker_rlimit_sigpending ==
'''Syntax:''' ''worker_rlimit_sigpending limit''

'''Default:''' '' ''

(Since Linux 2.6.8) Specifies the limit on the number of signals that may be queued for the real user ID of the calling process.

== working_directory ==
'''Syntax:''' ''working_directory path''

'''Default:''' ''--prefix''

This is the working directory for the workers. It's used for core files only and [[Debugging]] Nginx. nginx uses absolute paths only, all relative paths in configuration files are relative to <code>--prefix==PATH</code>.

= Variables =

== $pid ==
The process ID;

== $realpath_root ==
(undocumented)

= References =
